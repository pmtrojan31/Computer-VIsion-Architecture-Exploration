# -*- coding: utf-8 -*-
"""UNET-SAM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TW8TDx1OGqYrFHhY8KE07W2oFeM08TWO
"""

!pip install -r requirements.txt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.transforms import functional as TF
import segmentation_models_pytorch as smp
from segment_anything import sam_model_registry, SamPredictor
import numpy as np
import cv2
from PIL import Image
import os
import requests
import zipfile
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import pandas as pd
import random
import warnings
warnings.filterwarnings('ignore')

# gonna set up the device and random seeds for reproducibility
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

class CarvanaDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None, img_size=(256, 256)):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.img_size = img_size
        self.images = os.listdir(image_dir)[:500]  # using subset for faster training

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_dir, self.images[idx])
        mask_name = self.images[idx].replace('.jpg', '_mask.gif')
        mask_path = os.path.join(self.mask_dir, mask_name)

        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')

        # resize em to standard size
        image = image.resize(self.img_size)
        mask = mask.resize(self.img_size)

        if self.transform:
            image = self.transform(image)
            mask = TF.to_tensor(mask)
            mask = (mask > 0.5).float()

        return image, mask

def download_carvana_sample():
    """Downloads a sample of Carvana dataset if not present"""
    if not os.path.exists('carvana_data'):
        print("Dataset not found. Please download Carvana dataset from Kaggle")
        print("Using synthetic data for demonstration...")
        create_synthetic_data()
    return 'carvana_data/train', 'carvana_data/train_masks'

def create_synthetic_data():
    """Creates synthetic car-like segmentation data for demo"""
    os.makedirs('carvana_data/train', exist_ok=True)
    os.makedirs('carvana_data/train_masks', exist_ok=True)

    for i in range(50):  # create 50 synthetic samples
        # synthetic image with a car-like shape
        img = np.ones((256, 256, 3), dtype=np.uint8) * 200
        mask = np.zeros((256, 256), dtype=np.uint8)

        # draw a simple car shape
        cv2.rectangle(img, (80, 120), (176, 160), (50, 50, 150), -1)
        cv2.rectangle(img, (70, 140), (186, 180), (50, 50, 150), -1)
        cv2.circle(img, (100, 180), 15, (20, 20, 20), -1)
        cv2.circle(img, (156, 180), 15, (20, 20, 20), -1)

        cv2.rectangle(mask, (80, 120), (176, 160), 255, -1)
        cv2.rectangle(mask, (70, 140), (186, 180), 255, -1)

        # add some noise for variety
        noise = np.random.randint(0, 30, img.shape, dtype=np.uint8)
        img = cv2.add(img, noise)

        cv2.imwrite(f'carvana_data/train/img_{i:04d}.jpg', img)
        Image.fromarray(mask).save(f'carvana_data/train_masks/img_{i:04d}_mask.gif')

def calculate_dice_score(pred, target):
    """Calculate Dice coefficient"""
    smooth = 1e-6
    pred_flat = pred.reshape(-1)
    target_flat = target.reshape(-1)
    intersection = (pred_flat * target_flat).sum()
    return (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)

def train_unet(model, train_loader, val_loader, epochs=10):
    """Train the UNet model"""
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = CombinedLoss(dice_weight=0.5, bce_weight=0.5)

    print("\nTraining UNet...")
    for epoch in range(epochs):
        model.train()
        train_loss = 0

        for images, masks in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):
            images, masks = images.to(device), masks.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        avg_loss = train_loss / len(train_loader)
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')

    return model

def evaluate_model(model, test_loader, model_name="Model"):
    """Evaluate any model and return metrics"""
    if model_name == "UNet":
      model.eval()
    all_preds = []
    all_targets = []
    dice_scores = []

    print(f"\nEvaluating {model_name}...")
    with torch.no_grad():
        for images, masks in tqdm(test_loader):
            images, masks = images.to(device), masks.to(device)

            if model_name == "UNet":
                outputs = model(images)
                preds = (torch.sigmoid(outputs) > 0.5).float()
            else:  # SAM
                preds = predict_with_sam(model, images)
                preds = torch.from_numpy(preds).to(device)

            # flatten for sklearn metrics
            preds_flat = preds.cpu().numpy().flatten()
            masks_flat = masks.cpu().numpy().flatten()

            all_preds.extend(preds_flat)
            all_targets.extend(masks_flat)

            # calculate dice per image
            for i in range(preds.shape[0]):
                dice = calculate_dice_score(preds[i].cpu().numpy(), masks[i].cpu().numpy())
                dice_scores.append(dice)

    # convert to binary
    all_preds = (np.array(all_preds) > 0.5).astype(int)
    all_targets = (np.array(all_targets) > 0.5).astype(int)

    metrics = {
        'Model': model_name,
        'Precision': precision_score(all_targets, all_preds, zero_division=0),
        'Recall': recall_score(all_targets, all_preds, zero_division=0),
        'F1-Score': f1_score(all_targets, all_preds, zero_division=0),
        'Accuracy': accuracy_score(all_targets, all_preds),
        'Dice-Score': np.mean(dice_scores)
    }

    return metrics

def predict_with_sam(sam_predictor, images):
    """Use SAM for prediction with automatic mask generation"""
    batch_size = images.shape[0]
    predictions = np.zeros((batch_size, 1, 256, 256))

    for i in range(batch_size):
        # convert tensor to numpy and denormalize
        img = images[i].cpu().numpy().transpose(1, 2, 0)
        img = (img * 255).astype(np.uint8)

        sam_predictor.set_image(img)

        # use point prompts in center of image (assuming car is centered)
        h, w = img.shape[:2]
        input_points = np.array([[w//2, h//2], [w//3, h//2], [2*w//3, h//2]])
        input_labels = np.array([1, 1, 1])  # all foreground points

        masks, scores, _ = sam_predictor.predict(
            point_coords=input_points,
            point_labels=input_labels,
            multimask_output=True,
        )

        # pick the mask with highest score
        best_mask_idx = np.argmax(scores)
        predictions[i, 0] = masks[best_mask_idx]

    return predictions

def download_sam_checkpoint():
    """Download SAM checkpoint if not present"""
    checkpoint_path = 'sam_vit_b_01ec64.pth'
    if not os.path.exists(checkpoint_path):
        print("Downloading SAM checkpoint...")
        url = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth'
        response = requests.get(url, stream=True)
        total_size = int(response.headers.get('content-length', 0))

        with open(checkpoint_path, 'wb') as f:
            with tqdm(total=total_size, unit='B', unit_scale=True) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
                    pbar.update(len(chunk))
    return checkpoint_path

def main():
    # prep the data
    img_dir, mask_dir = download_carvana_sample()

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # create datasets
    dataset = CarvanaDataset(img_dir, mask_dir, transform=transform)

    # split into train, val, test
    train_size = int(0.7 * len(dataset))
    val_size = int(0.15 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )

    # dataloaders
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)

    print(f"Dataset sizes - Train: {train_size}, Val: {val_size}, Test: {test_size}")

    # initialize UNet using segmentation_models_pytorch
    print("\nInitializing UNet model...")
    unet = smp.Unet(
        encoder_name="resnet34",
        encoder_weights="imagenet",
        in_channels=3,
        classes=1,
        activation=None
    ).to(device)

    # train UNet
    unet = train_unet(unet, train_loader, val_loader, epochs=20)

    # initialize SAM
    print("\nInitializing SAM model...")
    checkpoint_path = download_sam_checkpoint()
    sam = sam_model_registry["vit_b"](checkpoint=checkpoint_path)
    sam.to(device)
    sam_predictor = SamPredictor(sam)

    # evaluate both models
    unet_metrics = evaluate_model(unet, test_loader, "UNet")
    sam_metrics = evaluate_model(sam_predictor, test_loader, "SAM")

    # create comparison table
    comparison_df = pd.DataFrame([unet_metrics, sam_metrics])
    comparison_df = comparison_df.set_index('Model')

    # format the numbers nicely
    for col in comparison_df.columns:
        comparison_df[col] = comparison_df[col].apply(lambda x: f"{x:.4f}")

    print("\n" + "="*70)
    print("COMPARISON TABLE: UNet vs SAM")
    print("="*70)
    print(comparison_df.to_string())
    print("="*70)

    # save results
    comparison_df.to_csv('segmentation_comparison_results.csv')
    print("\nResults saved to 'segmentation_comparison_results.csv'")

    # visualize some predictions
    visualize_predictions(unet, sam_predictor, test_loader)

def visualize_predictions(unet, sam_predictor, test_loader):
    """Visualize predictions from both models"""
    unet.eval()

    # get one batch for visualization
    images, masks = next(iter(test_loader))
    images, masks = images.to(device), masks.to(device)

    with torch.no_grad():
        unet_preds = (torch.sigmoid(unet(images)) > 0.5).float()

    sam_preds = predict_with_sam(sam_predictor, images)
    sam_preds = torch.from_numpy(sam_preds).to(device)

    # plot first image from batch
    fig, axes = plt.subplots(1, 4, figsize=(15, 4))

    # denormalize image for display
    img = images[0].cpu().numpy().transpose(1, 2, 0)
    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
    img = np.clip(img, 0, 1)

    axes[0].imshow(img)
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    axes[1].imshow(masks[0, 0].cpu().numpy(), cmap='gray')
    axes[1].set_title('Ground Truth')
    axes[1].axis('off')

    axes[2].imshow(unet_preds[0, 0].cpu().numpy(), cmap='gray')
    axes[2].set_title('UNet Prediction')
    axes[2].axis('off')

    axes[3].imshow(sam_preds[0, 0], cmap='gray')
    axes[3].set_title('SAM Prediction')
    axes[3].axis('off')

    plt.tight_layout()
    plt.savefig('segmentation_comparison.png', dpi=150, bbox_inches='tight')
    plt.show()
    print("\nVisualization saved to 'segmentation_comparison.png'")

if __name__ == "__main__":
    main()